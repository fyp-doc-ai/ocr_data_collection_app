{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chars import VOWEL_DIACRITICS, NUBERS_AND_PUNKTS, ALL_LETTERS\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(t):\n",
    "    tokenized_chars = []\n",
    "    for i, char in enumerate(t):\n",
    "        if char in VOWEL_DIACRITICS:\n",
    "            continue\n",
    "        if char in NUBERS_AND_PUNKTS:\n",
    "            # tokenized_chars.append(char)\n",
    "            continue\n",
    "        elif char == \" \":\n",
    "            tokenized_chars.append(\" \")\n",
    "        elif char in ALL_LETTERS:\n",
    "            if i < len(t) - 1 and t[i + 1] in ALL_LETTERS:\n",
    "                tokenized_chars.append(char)\n",
    "            elif i < len(t) - 1 and t[i + 1] in VOWEL_DIACRITICS:\n",
    "                tokenized_chars.append(char + t[i + 1])\n",
    "            else:\n",
    "                tokenized_chars.append(char)\n",
    "        else:\n",
    "            # tokenized_chars.append(char)\n",
    "            continue\n",
    "    return tokenized_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_LIMIT = 500\n",
    "MIN_CHARS = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3896/1718345 [00:01<12:54, 2214.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts: 500\n",
      "Total characters: 405\n",
      "{'දෙ': 49, 'න්': 441, 'න': 404, 'ගෙ': 42, 'ම': 453, ' ': 2876, 'වෙ': 77, 'ළෙ': 1, 'ඳ': 26, 'ආ': 62, 'ය': 414, 'ත': 206, 'යි': 89, 'ර': 333, 'ණ': 46, 'වැ': 46, 'ඩ': 45, 'ස': 238, 'ට': 303, 'හ': 132, 'ජී': 11, 'වී': 20, 'ගු': 25, 'ව': 418, 'වි': 122, 'දු': 61, 'ලි': 61, 'ඔ': 57, 'බ': 92, 'ගේ': 76, 'ප': 169, 'වු': 30, 'ලේ': 26, 'අ': 232, 'ත්': 209, 'දි': 52, 'චි': 15, 'නා': 58, 'ල': 184, 'ව්': 21, 'ගා': 13, 'මි': 62, 'ද': 172, 'පි': 66, 'ඉ': 87, 'නේ': 36, 'බි': 12, 'රි': 92, 'සි': 81, 'නි': 87, 'හු': 20, 'මු': 29, 'රු': 91, 'සේ': 21, 'වා': 73, 'භා': 15, 'වේ': 45, 'රූ': 3, 'හි': 64, 'නී': 12, 'තා': 44, 'ක්': 257, 'ෂ': 34, 'රේ': 19, 'කා': 76, 'ර්': 75, 'ග': 133, 'ගි': 28, 'ගෘ': 2, 'ස්': 138, 'ථ': 5, 'රී': 34, 'ඩා': 11, 'කැ': 17, 'ති': 152, 'මා': 75, 'පො': 14, 'ඩි': 20, 'එ': 122, 'ක': 379, 'ඒ': 52, 'ල්': 72, 'හැ': 35, 'නු': 34, 'බැ': 12, 'ලී': 6, 'කො': 32, 'සු': 47, 'හා': 38, 'ශ්': 30, 'දැ': 33, 'නෙ': 33, 'පේ': 14, 'ලු': 15, 'දේ': 31, 'ශ': 34, 'පා': 50, 'දා': 41, 'ළ': 33, 'ගැ': 27, 'ටු': 25, 'ඇ': 55, 'නැ': 37, 'ද්': 59, 'ණ්': 24, 'ඩු': 15, 'ලා': 58, 'ලෝ': 10, 'යේ': 42, 'සැ': 19, 'ප්': 61, 'තු': 80, 'ම්': 111, 'පැ': 19, 'යෝ': 16, 'යා': 109, 'සා': 33, 'ජ': 39, 'කෙ': 18, 'නෑ': 12, 'මේ': 67, 'යු': 28, 'පු': 47, 'කු': 28, 'කි': 70, 'ළි': 14, 'නො': 15, 'ච්': 16, 'රා': 35, 'ළේ': 1, 'ශේ': 4, 'බී': 1, 'ඟ': 7, 'ලෙ': 27, 'ලූ': 2, 'ළා': 8, 'මැ': 17, 'උ': 69, 'ග්': 8, 'ෂ්': 12, 'ධා': 10, 'සී': 11, 'ධි': 15, 'මෛ': 1, 'සං': 17, 'ධ': 26, 'ධී': 2, 'ඊ': 8, 'මෙ': 47, 'ජා': 21, 'ඳි': 1, 'ගෝ': 9, 'යැ': 3, 'ලං': 13, 'පෞ': 1, 'වෛ': 3, 'ධ්': 9, 'ඝ': 3, 'ජ්': 6, 'ට්': 22, 'ටේ': 6, 'ණි': 21, 'යෙ': 46, 'සෞ': 2, 'ඛ්': 3, 'ණී': 5, 'හෙ': 29, 'ණේ': 2, 'තූ': 4, 'ෆ්': 3, 'රෑ': 3, 'ළු': 21, 'වෝ': 11, 'ගො': 15, 'පෙ': 12, 'තෝ': 1, 'බූ': 6, 'වො': 4, 'සෙ': 12, 'ගී': 10, 'තො': 10, 'රෙ': 14, 'ෂි': 3, 'ෆ': 2, 'ඞ්': 2, 'ටි': 40, 'දී': 30, 'බු': 14, 'වූ': 9, 'රො': 5, 'ඩෝ': 1, 'තැ': 9, 'ශි': 5, 'ඛ': 2, 'බො': 18, 'තේ': 10, 'දෑ': 3, 'මං': 2, 'බා': 9, 'ණා': 5, 'ඹ': 17, 'රෝ': 4, 'ජි': 6, 'යො': 4, 'ඟු': 3, 'ණු': 8, 'මී': 9, 'හේ': 2, 'තෙ': 9, 'ථා': 12, 'පෘ': 1, 'ඕ': 14, 'කෑ': 1, 'මූ': 8, 'ච': 18, 'පං': 2, 'බ්': 12, 'හො': 21, 'ලො': 6, 'මො': 13, 'තී': 10, 'කේ': 16, 'රං': 8, 'සෝ': 1, 'නං': 2, 'ඨා': 8, 'ඝා': 2, 'ශී': 7, 'අා': 2, 'අං': 6, 'හ්': 2, 'මෝ': 8, 'බෙ': 7, 'දූ': 1, 'චූ': 1, 'ඌ': 2, 'බෑ': 3, 'ඳු': 11, 'බේ': 7, 'නෝ': 1, 'ථි': 5, 'ඵ': 3, 'කී': 5, 'ටං': 2, 'කෝ': 17, 'භෞ': 1, 'ඉං': 3, 'ඟා': 1, 'ඳෑ': 1, 'ඹු': 1, 'ලෑ': 2, 'හී': 2, 'භ': 11, 'ඨ': 3, 'ණො': 1, 'ඈ': 3, 'ඳී': 2, 'ඬ': 1, 'සො': 3, 'ටී': 4, 'උං': 1, 'ටෙ': 2, 'රැ': 11, 'චා': 14, 'හෝ': 20, 'භේ': 2, 'භි': 5, 'චෝ': 1, 'පී': 5, 'භ්': 1, 'ජේ': 1, 'කෘ': 7, 'ඬු': 1, 'පෝ': 4, 'වං': 1, 'ශා': 4, 'තෘ': 2, 'පූ': 4, 'ලැ': 9, 'ණෑ': 1, 'චී': 2, 'ෂො': 1, 'ඩී': 4, 'ඡ': 1, 'එං': 2, 'යෑ': 1, 'ෆේ': 3, 'ෂා': 7, 'ඩ්': 19, 'ඩං': 1, 'ඟි': 2, 'බෝ': 5, 'සෑ': 5, 'දෝ': 1, 'වෘ': 3, 'මෑ': 1, 'ටා': 2, 'ජෙ': 1, 'චෛ': 1, 'දො': 1, 'ෆො': 1, 'ටෝ': 1, 'ඩේ': 6, 'ටැ': 1, 'බං': 1, 'තෑ': 1, 'චං': 1, 'කූ': 1, 'ඩැ': 1, 'දෛ': 1, 'ජූ': 1, 'ජු': 3, 'ජෝ': 1, 'ශො': 1, 'ගෑ': 1, 'ඩො': 1, 'ෆි': 3, 'ඛු': 1, 'ඹේ': 4, 'ඛි': 1, 'ෂී': 1, 'ළො': 1, 'ගං': 1, 'යං': 2, 'හූ': 1, 'ශූ': 1, 'ඡ්': 1, 'ෂෙ': 1, 'භං': 1, 'ජං': 1, 'ධු': 2, 'සෘ': 1, 'ඹී': 1, 'චේ': 2, 'වෑ': 1, 'ෆෝ': 1, 'ඳං': 1, 'කං': 2, 'ඟේ': 1, 'සූ': 4, 'බෞ': 3, 'ටො': 3, 'ය්': 1, 'භූ': 3, 'ශෙ': 1, 'පෑ': 2, 'යෞ': 1, 'ශෝ': 2, 'ඳා': 1, 'ධූ': 1, 'ඡා': 1, 'ඩෙ': 1, 'ඹි': 1, 'ඳෙ': 1, 'ෂු': 1, 'ගෞ': 2, 'ඨං': 1, 'තං': 1, 'ශු': 3, 'ෂූ': 1, 'ඤා': 1, 'හං': 1, 'ඩෑ': 1, 'ඹෙ': 2, 'ළී': 1, 'ළැ': 1, 'ඡු': 1, 'චැ': 1, 'චු': 3, 'චෙ': 1, 'ජෑ': 1, 'යූ': 1, 'ඝෝ': 1, 'ෆු': 1, 'ටෑ': 1, 'ජැ': 1, 'ණෙ': 1, 'නෞ': 1, 'ටූ': 1, 'ඤ': 1, 'ෆී': 1, 'ඤ්': 1, 'ඤං': 1, 'ථ්': 1, 'භී': 1, 'ඳේ': 1, 'ෂෝ': 1, 'නූ': 1, 'ඔ්': 1, 'ළ්': 1, 'භෝ': 1, 'මෘ': 1, 'ඛෙ': 1, 'ණූ': 1, 'ළං': 1, 'ජො': 1, 'ඟෙ': 1, 'ඛී': 1, 'ඛා': 2, 'දෘ': 2, 'තෛ': 1, 'ජෛ': 1, 'ඡෙ': 1, 'ෆෙ': 1, 'කෞ': 1}\n"
     ]
    }
   ],
   "source": [
    "chars = dict()\n",
    "temp_chars = dict()\n",
    "count = 0\n",
    "with open('D:\\\\FYP\\\\text-handwriting-conversion\\\\si\\\\xaa', 'r', encoding='utf-8') as f:\n",
    "    for line in tqdm(f.readlines()):\n",
    "        max_words = random.randint(5,9)\n",
    "        if (count >= GT_LIMIT):\n",
    "            print(\"Total texts:\", count)\n",
    "            print(\"Total characters:\", len(chars))\n",
    "            print(chars)\n",
    "            with open('char_counts.pkl', 'wb') as f:\n",
    "                pickle.dump(chars,f)\n",
    "            break\n",
    "\n",
    "        text = line.strip()\n",
    "\n",
    "        text = re.sub(r'\\s*[A-Za-z.?()><,;:\\'\\\"!@#$%^&*\\-_+=`~“”–0-9\\/]+', '' , text)\n",
    "        text = text.strip()\n",
    "        \n",
    "        if(len(text) == 0):\n",
    "            continue\n",
    "        elif(len(text.split(' '))>max_words):\n",
    "            text = ' '.join(text.split(' ')[:max_words])\n",
    "        \n",
    "        init_len = len(chars)\n",
    "        temp_chars = copy.deepcopy(chars)\n",
    "\n",
    "        for char in process_text(text):\n",
    "            cur_count = temp_chars.get(char, 0)\n",
    "            temp_chars[char] = cur_count+1\n",
    "\n",
    "        final_len = len(temp_chars)\n",
    "        new_chars = final_len-init_len\n",
    "\n",
    "        if (new_chars > 0) or (len(chars) >= MIN_CHARS):\n",
    "            chars = copy.deepcopy(temp_chars)\n",
    "            with open('gt/gt_'+str(count)+'.txt', 'w', encoding='utf-8') as f:\n",
    "                f.write(text)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
